{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 115.948666,
     "end_time": "2025-04-04T13:53:13.746093",
     "exception": false,
     "start_time": "2025-04-04T13:51:17.797427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from common_stuff import *\n",
    "import os\n",
    "\n",
    "for gpu in [0, 1]: \n",
    "    signal_path = f'{model_temp_storage}_gpu{gpu}_done'\n",
    "    if os.path.exists(signal_path): os.rmdir(signal_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 5.286141,
     "end_time": "2025-04-04T13:53:19.060268",
     "exception": false,
     "start_time": "2025-04-04T13:53:13.774127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "GPU 0 Training Data Samples\n",
      "========================================\n",
      "GPU 0 assigned 60 training tasks\n",
      "\n",
      "========================================\n",
      "GPU 1 Training Data Samples\n",
      "========================================\n",
      "GPU 1 assigned 60 training tasks\n",
      "\n",
      "========================================\n",
      "GPU 2 Training Data Samples\n",
      "========================================\n",
      "GPU 2 assigned 60 training tasks\n",
      "\n",
      "========================================\n",
      "GPU 3 Training Data Samples\n",
      "========================================\n",
      "GPU 3 assigned 60 training tasks\n"
     ]
    }
   ],
   "source": [
    "# Simplified ARC data visualization script (English version)\n",
    "from arc_loader import *\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Load original data\n",
    "arc_challenge_file = './input/arc-prize-2025/arc-agi_test_challenges.json'\n",
    "with open(arc_challenge_file, 'r') as f:\n",
    "    arc_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.042624,
     "end_time": "2025-04-04T13:53:19.121504",
     "exception": false,
     "start_time": "2025-04-04T13:53:19.07888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin start_training()\n",
      "*** Load base model and tokenizer from './input/wb55l_nemomini_fulleval/transformers/default/1'...\n",
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aldri/fun/ml/ARC-2025/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.3.19: Fast Mistral patching. Transformers: 4.51.2.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4060 Laptop GPU. Num GPUs = 1. Max memory: 7.653 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MistralForCausalLM.__init__() got an unexpected keyword argument 'report_to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# %%python --bg --proc train_proc0\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcommon_stuff\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mstart_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fun/ml/ARC-2025/common_stuff.py:144\u001b[0m, in \u001b[0;36mstart_training\u001b[0;34m(gpu)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (gpu\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m multi_gpu_train) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(storage_path):\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m RemapCudaOOM():\n\u001b[0;32m--> 144\u001b[0m         model, formatter \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         dataset \u001b[38;5;241m=\u001b[39m prepare_dataset(formatter, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, gpu\u001b[38;5;241m=\u001b[39mgpu \u001b[38;5;28;01mif\u001b[39;00m multi_gpu_train \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    146\u001b[0m         model, trainer_stats \u001b[38;5;241m=\u001b[39m training_run(\n\u001b[1;32m    147\u001b[0m             model, formatter, dataset, store\u001b[38;5;241m=\u001b[39mstorage_path,\n\u001b[1;32m    148\u001b[0m             max_seq_length\u001b[38;5;241m=\u001b[39mmax_seq_length_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m             ),\n\u001b[1;32m    168\u001b[0m         )\n",
      "File \u001b[0;32m~/fun/ml/ARC-2025/common_stuff.py:70\u001b[0m, in \u001b[0;36mprepare_run\u001b[0;34m(model_path, load_lora, train, gpu, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_DEVICE_ORDER\u001b[39m\u001b[38;5;124m\"\u001b[39m   ] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCI_BUS_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(gpu)\n\u001b[0;32m---> 70\u001b[0m model, tokenizer, formatter \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# base model configuration\u001b[39;49;00m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munsloth_4bit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#shrink_embedding=8000,\u001b[39;49;00m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_seq_length_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMyFormatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpeft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\u001b[39;49;00m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mq_proj\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mk_proj\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mv_proj\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mo_proj\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgate_proj\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mup_proj\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdown_proj\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43membed_tokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlm_head\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlora_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlora_dropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Supports any, but = 0 is optimized\u001b[39;49;00m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnone\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Supports any, but = \"none\" is optimized\u001b[39;49;00m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_gradient_checkpointing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# True or \"unsloth\" for very long context\u001b[39;49;00m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_rslora\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# We support rank stabilized LoRA\u001b[39;49;00m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloftq_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# And LoftQ\u001b[39;49;00m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mload_lora\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mload_lora\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mload_lora\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train \u001b[38;5;129;01mand\u001b[39;00m mask_first: formatter\u001b[38;5;241m.\u001b[39mcollator_kwargs\u001b[38;5;241m.\u001b[39mupdate(mask_first_output\u001b[38;5;241m=\u001b[39mmask_first)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, formatter\n",
      "File \u001b[0;32m~/fun/ml/ARC-2025/model_runner.py:177\u001b[0m, in \u001b[0;36mprepare_model\u001b[0;34m(model, mode, tokenizer, formatter, shrink_embedding, dequantize, peft, local_files_only, add_special_tokens, set_pad_token, keep_tokens, keep_normalizer, peft_trainable, device_map, tf_grad_cp, tf_use_fa2, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsupported\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munsloth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n\u001b[0;32m--> 177\u001b[0m     model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mFastLanguageModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreport_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformers\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformers_bf16\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformers_4bit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformers_bf16_4bit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokenizer_only\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/fun/ml/ARC-2025/.venv/lib/python3.10/site-packages/unsloth/models/loader.py:363\u001b[0m, in \u001b[0;36mFastLanguageModel.from_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, load_in_8bit, full_finetuning, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, use_exact_model_name, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mdispatch_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_get_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_patcher\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdispatch_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_peft\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfast_inference\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfast_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfloat8_kv_cache\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfloat8_kv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_lora_rank\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_lora_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resize_model_vocab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     model\u001b[38;5;241m.\u001b[39mresize_token_embeddings(resize_model_vocab)\n",
      "File \u001b[0;32m~/fun/ml/ARC-2025/.venv/lib/python3.10/site-packages/unsloth/models/mistral.py:400\u001b[0m, in \u001b[0;36mFastMistralModel.from_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_pretrained\u001b[39m(\n\u001b[1;32m    387\u001b[0m     model_name        \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsloth/mistral-7b-bnb-4bit\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    399\u001b[0m ):\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFastLlamaModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfix_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_patcher\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFastMistralModel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtokenizer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fun/ml/ARC-2025/.venv/lib/python3.10/site-packages/unsloth/models/llama.py:1780\u001b[0m, in \u001b[0;36mFastLlamaModel.from_pretrained\u001b[0;34m(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, **kwargs)\u001b[0m\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit: kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m bnb_config\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fast_inference:\n\u001b[0;32m-> 1780\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1784\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# quantization_config     = bnb_config,\u001b[39;49;00m\n\u001b[1;32m   1785\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_position_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_position_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1787\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1788\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_implementation\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meager\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1789\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1791\u001b[0m     model\u001b[38;5;241m.\u001b[39mfast_generate \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate\n\u001b[1;32m   1792\u001b[0m     model\u001b[38;5;241m.\u001b[39mfast_generate_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/fun/ml/ARC-2025/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:571\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    570\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m )\n",
      "File \u001b[0;32m~/fun/ml/ARC-2025/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:279\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m~/fun/ml/ARC-2025/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:4342\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4336\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_autoset_attn_implementation(\n\u001b[1;32m   4337\u001b[0m         config, use_flash_attention_2\u001b[38;5;241m=\u001b[39muse_flash_attention_2, torch_dtype\u001b[38;5;241m=\u001b[39mtorch_dtype, device_map\u001b[38;5;241m=\u001b[39mdevice_map\n\u001b[1;32m   4338\u001b[0m     )\n\u001b[1;32m   4340\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(model_init_context):\n\u001b[1;32m   4341\u001b[0m     \u001b[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001b[39;00m\n\u001b[0;32m-> 4342\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4344\u001b[0m \u001b[38;5;66;03m# Make sure to tie the weights correctly\u001b[39;00m\n\u001b[1;32m   4345\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "\u001b[0;31mTypeError\u001b[0m: MistralForCausalLM.__init__() got an unexpected keyword argument 'report_to'"
     ]
    }
   ],
   "source": [
    "# %%python --bg --proc train_proc0\n",
    "from common_stuff import *\n",
    "start_training(gpu=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T13:53:19.406042Z",
     "iopub.status.busy": "2025-04-04T13:53:19.405477Z",
     "iopub.status.idle": "2025-04-04T13:53:19.415586Z",
     "shell.execute_reply": "2025-04-04T13:53:19.41447Z"
    },
    "papermill": {
     "duration": 0.032516,
     "end_time": "2025-04-04T13:53:19.418262",
     "exception": false,
     "start_time": "2025-04-04T13:53:19.385746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%python --bg --proc infer_proc0\n",
    "from common_stuff import *\n",
    "start_inference(gpu=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T13:53:19.830117Z",
     "iopub.status.busy": "2025-04-04T13:53:19.829328Z",
     "iopub.status.idle": "2025-04-04T14:08:44.63478Z",
     "shell.execute_reply": "2025-04-04T14:08:44.634113Z"
    },
    "papermill": {
     "duration": 924.842711,
     "end_time": "2025-04-04T14:08:44.63648",
     "exception": false,
     "start_time": "2025-04-04T13:53:19.793769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "proc_exit_codes = await wait_for_subprocesses(\n",
    "    train_proc0, train_proc1, train_proc2, train_proc3,\n",
    "    infer_proc0, infer_proc1, infer_proc2, infer_proc3,\n",
    "    print_output=True or arc_test_set.is_fake\n",
    ")\n",
    "print(f'*** Subprocesses exit codes: {proc_exit_codes}')\n",
    "assert all(x==0 for x in proc_exit_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T14:08:44.811356Z",
     "iopub.status.busy": "2025-04-04T14:08:44.810792Z",
     "iopub.status.idle": "2025-04-04T14:08:45.692749Z",
     "shell.execute_reply": "2025-04-04T14:08:45.692117Z"
    },
    "papermill": {
     "duration": 0.969844,
     "end_time": "2025-04-04T14:08:45.694257",
     "exception": false,
     "start_time": "2025-04-04T14:08:44.724413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write submission\n",
    "from common_stuff import *\n",
    "with RemapCudaOOM():\n",
    "    model, formatter, dataset = None, MyFormatter(), None\n",
    "    decoder = Decoder(formatter, arc_test_set.split_multi_replies(), n_guesses=2, frac_score=True).from_store(infer_params['store'])\n",
    "    if use_aug_score or arc_test_set.is_fake: decoder.calc_augmented_scores(model=model, store=score_temp_storage, **aug_score_params)\n",
    "    submission = arc_test_set.get_submission(decoder.run_selection_algo(submission_select_algo))\n",
    "    with open('submission.json', 'w') as f: json.dump(submission, f)\n",
    "    if arc_test_set.is_fake:\n",
    "        decoder.benchmark_selection_algos(selection_algorithms)\n",
    "        with open('submission.json') as f: reload_submission = json.load(f)\n",
    "        print('*** Reload score:', arc_test_set.validate_submission(reload_submission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T14:08:45.873159Z",
     "iopub.status.busy": "2025-04-04T14:08:45.872874Z",
     "iopub.status.idle": "2025-04-04T14:08:52.871766Z",
     "shell.execute_reply": "2025-04-04T14:08:52.871151Z"
    },
    "papermill": {
     "duration": 7.089823,
     "end_time": "2025-04-04T14:08:52.873753",
     "exception": false,
     "start_time": "2025-04-04T14:08:45.78393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualization for inference results from submission.json\n",
    "if arc_test_set.is_fake:\n",
    "    from common_stuff import *\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import colors\n",
    "    import json\n",
    "    import os\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"VISUALIZING RESULTS FROM SUBMISSION.JSON\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Check if submission file exists\n",
    "    submission_path = 'submission.json'\n",
    "    if not os.path.exists(submission_path):\n",
    "        print(f\"Submission file not found at {submission_path}\")\n",
    "    else:\n",
    "        print(f\"Found submission file: {submission_path}\")\n",
    "        \n",
    "        # Load submission data\n",
    "        with open(submission_path, 'r') as f:\n",
    "            submission_data = json.load(f)\n",
    "        \n",
    "        print(f\"Loaded submission with {len(submission_data)} tasks\")\n",
    "        \n",
    "        # ARC color map\n",
    "        cmap = colors.ListedColormap(\n",
    "            ['#000000', '#0074D9', '#FF4136', '#2ECC40', '#FFDC00',\n",
    "             '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "        norm = colors.Normalize(vmin=0, vmax=9)\n",
    "        \n",
    "        # Function to check if prediction is non-trivial (not just zeros)\n",
    "        def is_non_trivial_prediction(pred_array):\n",
    "            # Check if the prediction contains any non-zero values\n",
    "            return np.any(np.array(pred_array) > 0)\n",
    "        \n",
    "        # Function to visualize a single task result\n",
    "        def visualize_submission_result(task_id, task_data, submission_output, test_idx):\n",
    "            # Skip visualization if both predictions are just zeros\n",
    "            pred_1 = np.array(submission_output['attempt_1'])\n",
    "            pred_2 = np.array(submission_output['attempt_2'])\n",
    "            \n",
    "            if not is_non_trivial_prediction(pred_1) and not is_non_trivial_prediction(pred_2):\n",
    "                print(f\"  Skipping visualization for Task {task_id} - Test #{test_idx+1} (all predictions are zeros)\")\n",
    "                return False\n",
    "            \n",
    "            # Create visualization\n",
    "            fig = plt.figure(figsize=(15, 8))\n",
    "            grid_spec = plt.GridSpec(2, 3, width_ratios=[1, 1, 1])\n",
    "            \n",
    "            # Training examples (first one only for simplicity)\n",
    "            if task_data['train']:\n",
    "                # Train Input\n",
    "                ax1 = fig.add_subplot(grid_spec[0, 0])\n",
    "                ax1.imshow(task_data['train'][0]['input'], cmap=cmap, norm=norm)\n",
    "                ax1.grid(True, which='both', color='lightgrey', linewidth=0.5)\n",
    "                ax1.set_title(\"Training Input\")\n",
    "                ax1.set_xticks([])\n",
    "                ax1.set_yticks([])\n",
    "                \n",
    "                # Train Output\n",
    "                ax2 = fig.add_subplot(grid_spec[1, 0])\n",
    "                ax2.imshow(task_data['train'][0]['output'], cmap=cmap, norm=norm)\n",
    "                ax2.grid(True, which='both', color='lightgrey', linewidth=0.5)\n",
    "                ax2.set_title(\"Training Output\")\n",
    "                ax2.set_xticks([])\n",
    "                ax2.set_yticks([])\n",
    "            \n",
    "            # Test Input\n",
    "            if test_idx < len(task_data['test']):\n",
    "                ax3 = fig.add_subplot(grid_spec[0, 1])\n",
    "                ax3.imshow(task_data['test'][test_idx]['input'], cmap=cmap, norm=norm)\n",
    "                ax3.grid(True, which='both', color='lightgrey', linewidth=0.5)\n",
    "                ax3.set_title(f\"Test Input (Test #{test_idx+1})\")\n",
    "                ax3.set_xticks([])\n",
    "                ax3.set_yticks([])\n",
    "                \n",
    "                # Ground Truth (if available)\n",
    "                if 'output' in task_data['test'][test_idx]:\n",
    "                    ax4 = fig.add_subplot(grid_spec[1, 1])\n",
    "                    ax4.imshow(task_data['test'][test_idx]['output'], cmap=cmap, norm=norm)\n",
    "                    ax4.grid(True, which='both', color='lightgrey', linewidth=0.5)\n",
    "                    ax4.set_title(\"Ground Truth\")\n",
    "                    ax4.set_xticks([])\n",
    "                    ax4.set_yticks([])\n",
    "            \n",
    "            # Model Predictions\n",
    "            # Attempt 1\n",
    "            ax5 = fig.add_subplot(grid_spec[0, 2])\n",
    "            ax5.imshow(pred_1, cmap=cmap, norm=norm)\n",
    "            ax5.grid(True, which='both', color='lightgrey', linewidth=0.5)\n",
    "            ax5.set_title(\"Model Prediction (Attempt 1)\")\n",
    "            ax5.set_xticks([])\n",
    "            ax5.set_yticks([])\n",
    "            \n",
    "            # Attempt 2\n",
    "            ax6 = fig.add_subplot(grid_spec[1, 2])\n",
    "            ax6.imshow(pred_2, cmap=cmap, norm=norm)\n",
    "            ax6.grid(True, which='both', color='lightgrey', linewidth=0.5)\n",
    "            ax6.set_title(\"Model Prediction (Attempt 2)\")\n",
    "            ax6.set_xticks([])\n",
    "            ax6.set_yticks([])\n",
    "            \n",
    "            plt.suptitle(f\"Task {task_id} - Test Example #{test_idx+1}\", fontsize=16)\n",
    "            plt.tight_layout()\n",
    "            plt.subplots_adjust(top=0.9)\n",
    "            plt.show()\n",
    "            \n",
    "            # Calculate accuracy if ground truth is available\n",
    "            if 'output' in task_data['test'][test_idx]:\n",
    "                ground_truth = np.array(task_data['test'][test_idx]['output'])\n",
    "                \n",
    "                # Check accuracy of both attempts\n",
    "                results = []\n",
    "                match_1 = np.array_equal(pred_1, ground_truth) if is_non_trivial_prediction(pred_1) else False\n",
    "                results.append(f\"Attempt 1: {'âœ“' if match_1 else 'âœ—'}{' (zeros)' if not is_non_trivial_prediction(pred_1) else ''}\")\n",
    "                \n",
    "                match_2 = np.array_equal(pred_2, ground_truth) if is_non_trivial_prediction(pred_2) else False\n",
    "                results.append(f\"Attempt 2: {'âœ“' if match_2 else 'âœ—'}{' (zeros)' if not is_non_trivial_prediction(pred_2) else ''}\")\n",
    "                \n",
    "                print(f\"  Results: {', '.join(results)}\")\n",
    "                \n",
    "                # Display task statistics\n",
    "                print(f\"  Shape - Ground Truth: {ground_truth.shape}, Prediction 1: {pred_1.shape}, Prediction 2: {pred_2.shape}\")\n",
    "                print(f\"  Values - Ground Truth unique values: {np.unique(ground_truth)}\")\n",
    "                print(f\"          Prediction 1 unique values: {np.unique(pred_1)}\")\n",
    "                print(f\"          Prediction 2 unique values: {np.unique(pred_2)}\")\n",
    "            print()\n",
    "            return True\n",
    "        \n",
    "        # Process ALL results from submission (no limit)\n",
    "        visualized_count = 0\n",
    "        skipped_count = 0\n",
    "        \n",
    "        # Get a list of tasks in the submission\n",
    "        task_ids = list(submission_data.keys())\n",
    "        \n",
    "        # Collect all task/test combinations\n",
    "        all_predictions = []\n",
    "        for task_id in task_ids:\n",
    "            if task_id in arc_test_set.queries:\n",
    "                task_data = arc_test_set.queries[task_id]\n",
    "                for test_idx, test_prediction in enumerate(submission_data[task_id]):\n",
    "                    # Check if we have ground truth available\n",
    "                    has_ground_truth = (task_id in arc_test_set.replies and \n",
    "                                        test_idx < len(arc_test_set.replies[task_id]))\n",
    "                    \n",
    "                    # Check if predictions are non-trivial\n",
    "                    pred_1 = np.array(test_prediction['attempt_1'])\n",
    "                    pred_2 = np.array(test_prediction['attempt_2'])\n",
    "                    has_non_zero_pred = is_non_trivial_prediction(pred_1) or is_non_trivial_prediction(pred_2)\n",
    "                    \n",
    "                    # Score based on correctness if ground truth is available\n",
    "                    score = 0\n",
    "                    if has_ground_truth and has_non_zero_pred:\n",
    "                        ground_truth = np.array(arc_test_set.replies[task_id][test_idx])\n",
    "                        \n",
    "                        match_1 = np.array_equal(pred_1, ground_truth) if is_non_trivial_prediction(pred_1) else False\n",
    "                        match_2 = np.array_equal(pred_2, ground_truth) if is_non_trivial_prediction(pred_2) else False\n",
    "                        score = match_1 + match_2\n",
    "                        \n",
    "                    all_predictions.append((task_id, test_idx, score, has_ground_truth, has_non_zero_pred))\n",
    "        \n",
    "        # Sort by whether they have ground truth first, then by score\n",
    "        all_predictions.sort(key=lambda x: (-int(x[3]), -x[2]))\n",
    "        \n",
    "        # Print summary before visualization\n",
    "        print(f\"\\nFound {len(all_predictions)} total predictions to visualize\")\n",
    "        \n",
    "        # Visualize all tasks\n",
    "        for task_id, test_idx, score, has_ground_truth, has_non_zero_pred in all_predictions:\n",
    "            # Get task data and predictions\n",
    "            task_data = arc_test_set.queries[task_id]\n",
    "            submission_output = submission_data[task_id][test_idx]\n",
    "            \n",
    "            # Visualize this task\n",
    "            score_info = f\" (Score: {score}/2)\" if has_ground_truth and has_non_zero_pred else \" (no ground truth)\" if not has_ground_truth else \" (all zeros - no score)\"\n",
    "            print(f\"\\nTask: {task_id} - Test #{test_idx+1}{score_info}\")\n",
    "            \n",
    "            # Only increment visualized_count if actually visualized\n",
    "            if visualize_submission_result(task_id, task_data, submission_output, test_idx):\n",
    "                visualized_count += 1\n",
    "            else:\n",
    "                skipped_count += 1\n",
    "        \n",
    "        print(f\"\\nVisualized {visualized_count} inference results (skipped {skipped_count} with all-zero predictions)\")\n",
    "        \n",
    "        # Calculate overall accuracy statistics\n",
    "        if arc_test_set.is_fake:\n",
    "            total_tests = 0\n",
    "            total_scored_tests = 0\n",
    "            correct_attempt1 = 0\n",
    "            correct_attempt2 = 0\n",
    "            correct_any = 0\n",
    "            zero_predictions = 0\n",
    "            \n",
    "            for task_id, test_predictions in submission_data.items():\n",
    "                if task_id in arc_test_set.replies:\n",
    "                    for test_idx, test_prediction in enumerate(test_predictions):\n",
    "                        if test_idx < len(arc_test_set.replies[task_id]):\n",
    "                            total_tests += 1\n",
    "                            \n",
    "                            ground_truth = np.array(arc_test_set.replies[task_id][test_idx])\n",
    "                            pred_1 = np.array(test_prediction['attempt_1'])\n",
    "                            pred_2 = np.array(test_prediction['attempt_2'])\n",
    "                            \n",
    "                            # Check if both predictions are all zeros\n",
    "                            if not is_non_trivial_prediction(pred_1) and not is_non_trivial_prediction(pred_2):\n",
    "                                zero_predictions += 1\n",
    "                                continue\n",
    "                            \n",
    "                            # Only count tests with at least one non-zero prediction\n",
    "                            total_scored_tests += 1\n",
    "                            \n",
    "                            match_1 = np.array_equal(pred_1, ground_truth) if is_non_trivial_prediction(pred_1) else False\n",
    "                            match_2 = np.array_equal(pred_2, ground_truth) if is_non_trivial_prediction(pred_2) else False\n",
    "                            \n",
    "                            if match_1: correct_attempt1 += 1\n",
    "                            if match_2: correct_attempt2 += 1\n",
    "                            if match_1 or match_2: correct_any += 1\n",
    "            \n",
    "            if total_tests > 0:\n",
    "                print(\"\\n\" + \"=\"*80)\n",
    "                print(\"OVERALL ACCURACY STATISTICS\")\n",
    "                print(\"=\"*80)\n",
    "                print(f\"Total test examples: {total_tests}\")\n",
    "                print(f\"Test examples with zero predictions (excluded from accuracy): {zero_predictions}\")\n",
    "                print(f\"Test examples included in accuracy calculation: {total_scored_tests}\")\n",
    "                \n",
    "                if total_scored_tests > 0:\n",
    "                    print(f\"Correct on attempt 1: {correct_attempt1}/{total_scored_tests} ({correct_attempt1/total_scored_tests:.2%})\")\n",
    "                    print(f\"Correct on attempt 2: {correct_attempt2}/{total_scored_tests} ({correct_attempt2/total_scored_tests:.2%})\")\n",
    "                    print(f\"Correct on either attempt: {correct_any}/{total_scored_tests} ({correct_any/total_scored_tests:.2%})\")\n",
    "                else:\n",
    "                    print(\"No non-zero predictions to calculate accuracy\")\n",
    "                    \n",
    "                print(f\"Overall completion rate: {total_scored_tests/total_tests:.2%} of tests have non-zero predictions\")\n",
    "                print(\"=\"*80)\n",
    "else:\n",
    "    print(\"Skipping inference visualization - not in fake test mode\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11483707,
     "sourceId": 91496,
     "sourceType": "competition"
    },
    {
     "datasetId": 5793177,
     "sourceId": 9515958,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 157175,
     "modelInstanceId": 134422,
     "sourceId": 158171,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1059.350941,
   "end_time": "2025-04-04T14:08:54.10074",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-04T13:51:14.749799",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
